{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST 분류기\n",
    "- pytorch로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = './FASHION_MNIST_DATASET'\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(download_root, transform=transform, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(download_root, transform=transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset 개수 :  48000\n",
      "Validation dataset 개수 :  12000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셋을 학습 데이터 셋과 검증 데이터 셋으로 분리합니다.\n",
    "total_size = len(train_dataset)\n",
    "train_num, valid_num = int(total_size * 0.8), int(total_size * 0.2) # 8 : 2 = train : valid\n",
    "print(\"Train dataset 개수 : \", train_num)\n",
    "print(\"Validation dataset 개수 : \", valid_num)\n",
    "train_dataset,valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num]) # train - valid set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "tensor([7, 7, 1, 5, 6, 4, 2, 6, 1, 7, 8, 5, 6, 9, 2, 4, 8, 1, 1, 9, 7, 0, 3, 1,\n",
      "        7, 5, 6, 6, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dataloader:\n",
    "    print(images.shape)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x32e039d90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[3].squeeze().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=16),\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=16),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=32),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=32),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=128),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=128),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(num_features=128),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.block4 = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(7*7*128, 1024),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(1024, 564),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(564, 10),\n",
    "            torch.nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        output = self.block4(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "       BatchNorm2d-3           [-1, 16, 28, 28]              32\n",
      "            Conv2d-4           [-1, 16, 28, 28]           2,320\n",
      "              ReLU-5           [-1, 16, 28, 28]               0\n",
      "       BatchNorm2d-6           [-1, 16, 28, 28]              32\n",
      "         MaxPool2d-7           [-1, 16, 28, 28]               0\n",
      "            Conv2d-8           [-1, 32, 28, 28]           4,640\n",
      "              ReLU-9           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-10           [-1, 32, 28, 28]              64\n",
      "           Conv2d-11           [-1, 32, 28, 28]           9,248\n",
      "             ReLU-12           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-13           [-1, 32, 28, 28]              64\n",
      "        MaxPool2d-14           [-1, 32, 14, 14]               0\n",
      "           Conv2d-15          [-1, 128, 14, 14]          36,992\n",
      "             ReLU-16          [-1, 128, 14, 14]               0\n",
      "      BatchNorm2d-17          [-1, 128, 14, 14]             256\n",
      "           Conv2d-18          [-1, 128, 14, 14]         147,584\n",
      "             ReLU-19          [-1, 128, 14, 14]               0\n",
      "      BatchNorm2d-20          [-1, 128, 14, 14]             256\n",
      "           Conv2d-21          [-1, 128, 14, 14]         147,584\n",
      "             ReLU-22          [-1, 128, 14, 14]               0\n",
      "      BatchNorm2d-23          [-1, 128, 14, 14]             256\n",
      "        MaxPool2d-24            [-1, 128, 7, 7]               0\n",
      "          Flatten-25                 [-1, 6272]               0\n",
      "           Linear-26                 [-1, 1024]       6,423,552\n",
      "             ReLU-27                 [-1, 1024]               0\n",
      "           Linear-28                  [-1, 564]         578,100\n",
      "             ReLU-29                  [-1, 564]               0\n",
      "           Linear-30                   [-1, 10]           5,650\n",
      "       LogSoftmax-31                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 7,356,790\n",
      "Trainable params: 7,356,790\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.71\n",
      "Params size (MB): 28.06\n",
      "Estimated Total Size (MB): 31.78\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=((1, 28, 28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7356790"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dataloader, train_dataset, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    tbar = tqdm.tqdm(train_dataloader)\n",
    "\n",
    "    for images, labels in tbar:\n",
    "        print(labels)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b884ed57a3a4c7199b833788835856f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 7, 5, 1, 2, 1, 4, 9, 0, 6, 8, 0, 5, 8, 6, 9, 5, 9, 6, 9, 6, 0, 4,\n",
      "        6, 1, 6, 4, 5, 9, 0, 3])\n",
      "tensor([7, 5, 9, 9, 7, 3, 7, 3, 2, 9, 8, 8, 1, 1, 5, 8, 7, 3, 1, 6, 3, 5, 9, 9,\n",
      "        5, 9, 5, 9, 4, 6, 3, 5])\n",
      "tensor([9, 1, 7, 5, 2, 5, 8, 8, 9, 8, 0, 2, 1, 3, 7, 8, 0, 8, 7, 2, 0, 5, 8, 7,\n",
      "        6, 3, 5, 6, 1, 8, 3, 1])\n",
      "tensor([3, 2, 4, 3, 7, 0, 1, 1, 3, 4, 8, 0, 3, 2, 0, 1, 4, 8, 6, 6, 6, 8, 1, 4,\n",
      "        2, 2, 7, 3, 2, 2, 5, 3])\n",
      "tensor([5, 4, 5, 5, 7, 2, 2, 3, 8, 4, 0, 6, 3, 3, 9, 4, 4, 2, 1, 5, 4, 3, 9, 3,\n",
      "        7, 6, 3, 3, 3, 2, 4, 6])\n",
      "tensor([2, 8, 6, 9, 4, 9, 0, 0, 5, 4, 0, 8, 9, 0, 4, 0, 7, 8, 3, 6, 6, 2, 9, 7,\n",
      "        9, 6, 6, 1, 2, 9, 5, 9])\n",
      "tensor([1, 7, 5, 7, 1, 4, 8, 6, 7, 0, 3, 5, 3, 9, 4, 8, 7, 1, 5, 2, 3, 5, 3, 8,\n",
      "        7, 9, 9, 1, 8, 3, 3, 5])\n",
      "tensor([3, 1, 0, 3, 8, 4, 7, 6, 5, 7, 8, 2, 3, 5, 9, 4, 7, 5, 8, 4, 9, 9, 9, 1,\n",
      "        6, 8, 4, 7, 4, 6, 8, 5])\n",
      "tensor([8, 4, 2, 5, 3, 4, 8, 9, 7, 6, 3, 5, 9, 0, 8, 7, 2, 0, 3, 0, 2, 8, 9, 1,\n",
      "        9, 4, 0, 4, 4, 7, 2, 4])\n",
      "tensor([0, 2, 0, 7, 6, 1, 6, 9, 7, 7, 3, 1, 2, 9, 8, 0, 1, 2, 1, 7, 6, 6, 7, 9,\n",
      "        0, 9, 0, 7, 0, 2, 0, 8])\n",
      "tensor([2, 2, 3, 8, 2, 4, 9, 9, 8, 6, 2, 7, 3, 5, 2, 2, 4, 2, 8, 3, 2, 7, 7, 1,\n",
      "        6, 4, 8, 3, 2, 9, 3, 0])\n",
      "tensor([1, 7, 3, 2, 2, 9, 8, 0, 7, 4, 4, 9, 0, 8, 1, 6, 8, 5, 9, 0, 0, 7, 2, 4,\n",
      "        4, 6, 8, 4, 6, 8, 9, 6])\n",
      "tensor([5, 4, 8, 0, 7, 0, 8, 8, 1, 7, 8, 9, 3, 1, 5, 9, 6, 3, 0, 1, 1, 2, 4, 6,\n",
      "        3, 8, 8, 7, 3, 3, 5, 2])\n",
      "tensor([5, 6, 3, 7, 1, 8, 6, 1, 7, 8, 5, 5, 7, 3, 3, 8, 5, 7, 9, 9, 1, 9, 2, 5,\n",
      "        4, 3, 4, 5, 6, 0, 7, 4])\n",
      "tensor([5, 8, 4, 6, 0, 4, 4, 2, 8, 4, 0, 5, 8, 5, 5, 9, 0, 9, 3, 7, 4, 2, 8, 9,\n",
      "        3, 5, 5, 7, 0, 5, 0, 6])\n",
      "tensor([7, 0, 8, 8, 2, 6, 5, 1, 0, 6, 4, 6, 8, 0, 4, 6, 1, 5, 0, 8, 8, 5, 5, 9,\n",
      "        1, 8, 6, 7, 3, 4, 0, 1])\n",
      "tensor([9, 6, 4, 3, 0, 1, 5, 4, 8, 5, 7, 1, 0, 7, 0, 4, 4, 6, 8, 6, 1, 6, 8, 7,\n",
      "        3, 2, 5, 1, 1, 4, 2, 5])\n",
      "tensor([5, 2, 7, 3, 7, 8, 1, 9, 4, 3, 1, 3, 0, 9, 7, 4, 6, 8, 4, 6, 1, 6, 2, 0,\n",
      "        7, 8, 3, 4, 1, 7, 2, 8])\n",
      "tensor([7, 9, 6, 3, 4, 2, 7, 0, 7, 9, 7, 3, 1, 8, 2, 5, 6, 2, 3, 1, 8, 0, 7, 5,\n",
      "        4, 5, 5, 5, 4, 3, 9, 3])\n",
      "tensor([1, 7, 0, 9, 9, 2, 9, 0, 0, 3, 0, 5, 6, 3, 7, 4, 0, 2, 0, 4, 8, 8, 5, 2,\n",
      "        6, 1, 5, 5, 8, 1, 0, 8])\n",
      "tensor([5, 7, 8, 0, 3, 2, 9, 3, 6, 0, 4, 1, 9, 6, 1, 4, 5, 0, 6, 6, 5, 2, 3, 2,\n",
      "        7, 0, 8, 4, 2, 9, 2, 2])\n",
      "tensor([1, 9, 2, 5, 6, 4, 4, 5, 0, 1, 9, 7, 0, 1, 1, 2, 9, 4, 2, 6, 2, 6, 4, 5,\n",
      "        1, 1, 4, 9, 2, 4, 3, 3])\n",
      "tensor([4, 2, 5, 5, 2, 7, 2, 9, 4, 9, 7, 6, 2, 6, 8, 2, 3, 9, 6, 8, 8, 5, 8, 0,\n",
      "        3, 6, 0, 3, 0, 8, 0, 3])\n",
      "tensor([0, 5, 6, 0, 1, 8, 3, 7, 4, 3, 3, 4, 9, 0, 0, 1, 1, 4, 8, 7, 6, 5, 8, 5,\n",
      "        6, 5, 2, 5, 8, 1, 8, 7])\n",
      "tensor([6, 0, 2, 5, 7, 7, 7, 0, 4, 9, 7, 1, 9, 6, 5, 9, 2, 6, 8, 6, 7, 0, 4, 9,\n",
      "        4, 6, 9, 7, 6, 7, 4, 3])\n",
      "tensor([1, 6, 5, 3, 3, 9, 4, 2, 4, 5, 1, 6, 1, 6, 2, 8, 4, 8, 1, 8, 7, 0, 4, 2,\n",
      "        9, 6, 6, 8, 1, 4, 0, 9])\n",
      "tensor([1, 1, 2, 0, 4, 5, 6, 5, 2, 0, 2, 3, 8, 9, 1, 2, 6, 0, 2, 5, 9, 1, 3, 6,\n",
      "        2, 8, 8, 5, 2, 2, 6, 5])\n",
      "tensor([0, 0, 0, 5, 2, 9, 0, 9, 1, 2, 9, 2, 3, 7, 2, 4, 4, 0, 4, 6, 1, 1, 2, 6,\n",
      "        1, 2, 8, 5, 2, 6, 7, 2])\n",
      "tensor([7, 3, 8, 1, 4, 6, 4, 8, 4, 3, 8, 8, 7, 1, 2, 7, 3, 1, 1, 6, 8, 8, 6, 8,\n",
      "        4, 8, 7, 0, 0, 9, 1, 4])\n",
      "tensor([7, 6, 6, 9, 3, 9, 7, 5, 3, 8, 4, 3, 5, 9, 3, 2, 1, 9, 7, 4, 0, 7, 0, 1,\n",
      "        9, 5, 7, 3, 6, 5, 7, 4])\n",
      "tensor([7, 8, 0, 9, 0, 8, 9, 3, 5, 6, 3, 0, 5, 8, 1, 1, 4, 0, 4, 7, 0, 1, 4, 1,\n",
      "        5, 6, 0, 1, 8, 4, 4, 1])\n",
      "tensor([3, 0, 7, 9, 7, 6, 4, 2, 6, 1, 1, 1, 5, 9, 9, 8, 9, 2, 1, 6, 2, 4, 3, 4,\n",
      "        3, 6, 6, 8, 1, 9, 7, 6])\n",
      "tensor([5, 2, 1, 4, 0, 0, 9, 9, 2, 6, 0, 4, 1, 2, 5, 7, 9, 9, 1, 0, 7, 9, 2, 0,\n",
      "        8, 8, 0, 3, 0, 1, 2, 1])\n",
      "tensor([2, 5, 0, 4, 4, 6, 4, 6, 3, 3, 3, 7, 1, 4, 4, 6, 9, 2, 0, 5, 2, 2, 6, 7,\n",
      "        4, 6, 9, 2, 8, 6, 1, 5])\n",
      "tensor([8, 4, 1, 5, 7, 9, 6, 6, 0, 9, 2, 0, 3, 8, 5, 7, 6, 0, 3, 2, 7, 2, 9, 2,\n",
      "        7, 9, 1, 5, 7, 4, 7, 8])\n",
      "tensor([9, 2, 5, 8, 6, 4, 7, 0, 6, 4, 9, 2, 2, 2, 7, 6, 3, 5, 8, 1, 4, 2, 4, 6,\n",
      "        6, 6, 2, 8, 6, 7, 7, 6])\n",
      "tensor([2, 4, 3, 3, 3, 7, 3, 4, 7, 8, 8, 6, 5, 7, 6, 9, 9, 1, 3, 2, 0, 7, 8, 0,\n",
      "        4, 2, 7, 1, 0, 2, 5, 3])\n",
      "tensor([1, 3, 8, 0, 3, 6, 8, 6, 1, 3, 5, 1, 7, 5, 5, 6, 7, 1, 9, 6, 1, 8, 2, 8,\n",
      "        9, 2, 6, 1, 4, 2, 0, 4])\n",
      "tensor([7, 8, 0, 6, 7, 9, 0, 4, 3, 6, 1, 5, 0, 5, 4, 7, 4, 6, 0, 5, 2, 1, 6, 8,\n",
      "        4, 4, 5, 1, 7, 0, 6, 7])\n",
      "tensor([4, 9, 7, 5, 1, 1, 9, 8, 1, 3, 3, 2, 6, 4, 3, 0, 4, 1, 8, 0, 9, 9, 4, 5,\n",
      "        2, 6, 7, 8, 0, 2, 8, 8])\n",
      "tensor([6, 1, 7, 6, 8, 8, 1, 9, 9, 7, 4, 9, 4, 3, 5, 4, 1, 7, 9, 2, 2, 8, 0, 2,\n",
      "        0, 8, 2, 9, 6, 0, 4, 0])\n",
      "tensor([2, 6, 5, 1, 8, 6, 3, 3, 5, 6, 0, 0, 6, 9, 3, 9, 4, 9, 7, 1, 5, 1, 8, 1,\n",
      "        3, 7, 3, 4, 3, 6, 6, 6])\n",
      "tensor([1, 9, 6, 4, 2, 5, 0, 3, 2, 7, 2, 9, 1, 1, 1, 5, 9, 5, 7, 6, 0, 0, 4, 4,\n",
      "        6, 7, 8, 8, 9, 9, 7, 0])\n",
      "tensor([7, 7, 2, 4, 9, 0, 9, 4, 6, 6, 6, 0, 1, 0, 2, 4, 2, 0, 3, 7, 0, 4, 8, 2,\n",
      "        3, 2, 0, 6, 7, 4, 6, 1])\n",
      "tensor([9, 0, 2, 7, 1, 5, 8, 5, 9, 3, 1, 1, 0, 8, 0, 0, 8, 4, 8, 3, 9, 7, 8, 5,\n",
      "        1, 0, 7, 4, 9, 6, 4, 9])\n",
      "tensor([2, 9, 0, 9, 4, 1, 0, 5, 7, 9, 3, 0, 7, 3, 2, 4, 7, 3, 9, 9, 2, 5, 7, 1,\n",
      "        0, 1, 0, 1, 4, 2, 8, 4])\n",
      "tensor([3, 8, 1, 7, 3, 7, 6, 1, 7, 3, 6, 0, 0, 3, 3, 7, 5, 3, 1, 0, 6, 8, 0, 6,\n",
      "        2, 5, 3, 9, 4, 7, 3, 2])\n",
      "tensor([7, 2, 3, 5, 2, 4, 5, 9, 6, 4, 3, 7, 8, 9, 8, 8, 3, 5, 1, 1, 4, 3, 8, 2,\n",
      "        2, 7, 5, 9, 6, 1, 9, 4])\n",
      "tensor([6, 3, 2, 1, 7, 6, 1, 3, 3, 3, 1, 5, 2, 9, 3, 5, 1, 9, 7, 7, 8, 3, 4, 2,\n",
      "        8, 0, 2, 8, 9, 4, 1, 4])\n",
      "tensor([7, 8, 2, 7, 3, 5, 3, 1, 1, 2, 5, 9, 1, 7, 7, 7, 9, 3, 0, 9, 6, 7, 3, 2,\n",
      "        2, 2, 4, 6, 9, 3, 2, 2])\n",
      "tensor([9, 9, 7, 0, 4, 1, 4, 7, 2, 2, 2, 0, 9, 9, 7, 8, 0, 4, 0, 7, 9, 9, 0, 7,\n",
      "        2, 0, 9, 8, 6, 6, 9, 0])\n",
      "tensor([0, 7, 3, 0, 9, 4, 1, 7, 1, 9, 9, 8, 9, 0, 3, 9, 6, 6, 0, 8, 9, 2, 3, 3,\n",
      "        6, 0, 3, 7, 2, 9, 5, 0])\n",
      "tensor([9, 7, 9, 7, 5, 6, 9, 7, 9, 6, 6, 0, 6, 8, 2, 0, 6, 5, 1, 4, 7, 9, 0, 1,\n",
      "        8, 6, 9, 6, 3, 9, 2, 3])\n",
      "tensor([7, 9, 7, 9, 9, 5, 1, 2, 3, 8, 9, 2, 1, 3, 3, 0, 1, 1, 5, 1, 2, 9, 3, 2,\n",
      "        2, 3, 1, 5, 5, 0, 6, 6])\n",
      "tensor([3, 0, 0, 8, 2, 4, 6, 4, 9, 6, 6, 0, 9, 5, 5, 6, 4, 6, 7, 0, 9, 9, 5, 8,\n",
      "        7, 4, 1, 1, 5, 0, 9, 1])\n",
      "tensor([3, 9, 7, 5, 4, 3, 7, 8, 2, 3, 9, 1, 5, 3, 5, 9, 6, 9, 5, 8, 8, 4, 7, 7,\n",
      "        3, 2, 7, 5, 3, 7, 5, 6])\n",
      "tensor([7, 4, 6, 1, 1, 1, 3, 9, 9, 5, 7, 4, 8, 4, 4, 5, 8, 8, 9, 3, 2, 0, 6, 0,\n",
      "        7, 6, 2, 4, 5, 5, 1, 4])\n",
      "tensor([0, 3, 4, 3, 2, 7, 4, 0, 4, 5, 1, 5, 3, 1, 9, 5, 6, 8, 5, 9, 9, 9, 6, 9,\n",
      "        6, 7, 8, 6, 6, 6, 9, 3])\n",
      "tensor([4, 7, 7, 3, 8, 7, 2, 8, 0, 0, 8, 9, 8, 8, 5, 7, 6, 8, 8, 7, 5, 2, 8, 6,\n",
      "        8, 9, 6, 5, 3, 7, 6, 7])\n",
      "tensor([2, 7, 7, 7, 8, 9, 6, 4, 2, 6, 3, 3, 9, 2, 8, 0, 1, 8, 4, 6, 9, 6, 2, 5,\n",
      "        7, 8, 3, 3, 9, 5, 1, 5])\n",
      "tensor([5, 0, 9, 3, 7, 2, 1, 5, 7, 1, 9, 7, 5, 1, 9, 5, 2, 6, 5, 4, 9, 0, 8, 6,\n",
      "        1, 6, 9, 3, 3, 8, 9, 6])\n",
      "tensor([4, 3, 0, 6, 4, 8, 7, 0, 9, 7, 4, 6, 5, 0, 3, 4, 6, 5, 0, 6, 2, 3, 8, 8,\n",
      "        0, 8, 8, 2, 8, 4, 4, 3])\n",
      "tensor([2, 7, 2, 5, 2, 2, 4, 0, 2, 2, 0, 9, 1, 3, 5, 9, 6, 2, 8, 5, 4, 3, 4, 8,\n",
      "        5, 4, 8, 9, 1, 5, 9, 2])\n",
      "tensor([7, 0, 7, 3, 2, 6, 6, 7, 5, 5, 6, 9, 1, 8, 9, 0, 9, 4, 2, 9, 2, 2, 8, 9,\n",
      "        9, 4, 3, 0, 3, 5, 4, 8])\n",
      "tensor([6, 5, 4, 8, 3, 9, 4, 6, 9, 2, 8, 0, 6, 0, 3, 1, 7, 9, 1, 9, 4, 1, 2, 8,\n",
      "        3, 7, 5, 2, 4, 3, 2, 2])\n",
      "tensor([1, 9, 1, 6, 3, 0, 9, 0, 9, 6, 5, 0, 1, 0, 7, 4, 0, 7, 1, 8, 7, 7, 4, 5,\n",
      "        6, 4, 5, 5, 0, 9, 8, 3])\n",
      "tensor([5, 3, 7, 3, 6, 2, 4, 9, 7, 2, 3, 9, 5, 2, 6, 8, 8, 4, 8, 9, 1, 0, 4, 5,\n",
      "        1, 5, 7, 3, 2, 4, 7, 8])\n",
      "tensor([5, 3, 5, 9, 2, 8, 8, 1, 7, 9, 8, 8, 1, 3, 5, 2, 7, 4, 9, 2, 8, 2, 1, 5,\n",
      "        1, 6, 9, 9, 0, 0, 1, 3])\n",
      "tensor([6, 7, 2, 4, 3, 6, 7, 3, 3, 9, 7, 3, 7, 2, 6, 5, 1, 6, 9, 3, 7, 6, 7, 0,\n",
      "        8, 5, 8, 6, 0, 5, 1, 6])\n",
      "tensor([9, 1, 9, 0, 2, 1, 5, 9, 8, 3, 2, 7, 7, 8, 1, 3, 1, 6, 2, 5, 0, 6, 0, 5,\n",
      "        6, 0, 5, 1, 3, 5, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model = training(model, train_dataloader, train_dataset, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b59ba074e9a4f73bc5271c9b8aca7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\ntotal_preds = np.array(total_preds)\\ntotal_labels = np.array(total_labels)\\ncustom_cnn_acc = accuracy_score(total_labels, total_preds) # 정확도 계산\\nprint(\"Custom CNN model accuracy : \", custom_cnn_acc)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "total_labels = []\n",
    "total_preds = []\n",
    "with torch.no_grad():\n",
    "    tbar = tqdm.tqdm(test_dataloader)\n",
    "    for images, labels in tbar:\n",
    "        outputs = model(images)\n",
    "        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        \n",
    "        total_preds.extend(predicted.tolist())\n",
    "        total_labels.extend(labels.tolist())\n",
    "\n",
    "'''\n",
    "total_preds = np.array(total_preds)\n",
    "total_labels = np.array(total_labels)\n",
    "custom_cnn_acc = accuracy_score(total_labels, total_preds) # 정확도 계산\n",
    "print(\"Custom CNN model accuracy : \", custom_cnn_acc)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
